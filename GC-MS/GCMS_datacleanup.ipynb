{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Please ensure that this script is in the same directory as the text file (Mona_experimental_ms.txt)\n",
    "Run the following code block in sequence, some code block might take up to half an hour (depending on computer speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm  #instant showing the progress of loops \n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\n",
    "    'Name', \n",
    "    'Formula',\n",
    "    'MW',\n",
    "    'Exact Mass',\n",
    "    'NIST#',\n",
    "    'InChIKey', \n",
    "    'RI_estimated'\n",
    "    'RI_predicted'\n",
    "    'MS'\n",
    "    'Score'\n",
    "    #ms intensity\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_filename = 'GCMS-NIST20-example.txt' # name of the raw data text file\n",
    "foldername = 'GCMS_output' # this is the folder that we are going to store our cleaned data\n",
    "ignore = False # variable used to determine whether to exclude the element\n",
    "file_exist = True # variable used to determine whether the file that we are going to append exist or not\n",
    "repeating_key = False # variable used to determine whether there are multiple fields with same name in the element\n",
    "item_dict = {} # dictionary to store all the fields and value for an element\n",
    "string = '' # element in string form that are going to be written into error.txt when we can't decide its filename\n",
    "filename = '' # name of the file to store the cleaned data\n",
    "inchikey, mw= '','' # these variables are used to determine whether to include or exclude the element\n",
    "\n",
    "if not (os.path.exists(foldername)):\n",
    "    os.makedirs(foldername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This code block might take around 8 minutes to run\n",
    "\n",
    "with open(txt_filename, mode='r', encoding='utf-8-sig') as readf:\n",
    "    while True:\n",
    "        row = readf.readline()\n",
    "        \n",
    "        #use name as the collection starts\n",
    "        if (row == 'Name'):\n",
    "            readf.readline()\n",
    "            \n",
    "            # We ignore the current item if InChIKey is missing\n",
    "            if not(inchikey):\n",
    "                ignore = True\n",
    "            \n",
    "            if not (ignore):\n",
    "                # if there are multiple fields with same name in the current element,\n",
    "                # we output them into repeating_key.csv for further debugging purpose\n",
    "                if (repeating_key):\n",
    "                    filename = os.path.join(os.getcwd(), 'repeating_key.csv')\n",
    "\n",
    "                if (filename):\n",
    "                        \n",
    "                    file_exist = os.path.isfile(filename)\n",
    "\n",
    "                    with open(filename, 'a', encoding='utf-8-sig', newline='') as writef:\n",
    "                        writer = csv.writer(writef)\n",
    "                        if not (file_exist):\n",
    "                            writer.writerow(header)\n",
    "                        \n",
    "                        ms = item_dict['MS']\n",
    "                        score = item_dict['Score']\n",
    "                        while (len(ms) > 0):\n",
    "                            item_dict['MS'] = ms.pop(0)\n",
    "                            item_dict['Score'] = score.pop(0)\n",
    "                            writer.writerow(item_dict.get(col, '') for col in header)\n",
    "\n",
    "                else:\n",
    "                    # Will generate error.txt when:\n",
    "                    # 1. PrecursorMZ and MW are both not found\n",
    "                    # 2. There is trailing space or newline at the end of the file\n",
    "                    with open('error.txt', 'a', encoding='utf-8-sig') as writef:\n",
    "                        writef.write(string)\n",
    "                        writef.write('\\n')\n",
    "                    \n",
    "            # reinitialize everything after writing an item into a file\n",
    "            ignore = False\n",
    "            file_exist = True\n",
    "            repeating_key = False\n",
    "            item_dict = {}\n",
    "            string = ''\n",
    "            filename = ''\n",
    "            inchikey= ''\n",
    "            \n",
    "            if (row == 'Name'):\n",
    "                break # break out of the loop when we reach EOF\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        # Store InChIKey if it exists, used for InChIKey existence check later on\n",
    "        if ('InChIKey: ' in row):\n",
    "            inchikey = row.strip('\\n').split(\": \")[1]\n",
    "        \n",
    "        # exclude these fields\n",
    "#         if ('Synon: ' in row or 'Comments: ' in row or 'Num Peaks: ' in row):\n",
    "        if ('Synonyms: ' in row or 'Values and Intensities: ' in row):\n",
    "            continue\n",
    "\n",
    "        \n",
    "            \n",
    "        # determine the filename by using either PrecursorMZ or MW+1\n",
    "        # (MW+1 is used if PrecursorMZ does not exist or PrecursorMZ is equals to -1/0/1)\n",
    "        #NIST use MW for filename\n",
    "        if (not filename):\n",
    "#             if ('MW: ' in row):\n",
    "#                 try:\n",
    "#                     filename = os.path.join(os.getcwd(), foldername, str(int(float(row.strip('\\n').split(\": \")[1]))) + '.csv')\n",
    "#                     precursor_mz = int(float(row.strip('\\n').split(\": \")[1]))\n",
    "#                     if (precursor_mz == -1 or precursor_mz == 0 or precursor_mz == 1):\n",
    "#                         filename = ''\n",
    "#                 except ValueError:\n",
    "#                     print('ValueError: ', row)\n",
    "#                     break\n",
    "            if ('MW: ' in row):\n",
    "                try:\n",
    "                    filename = os.path.join(os.getcwd(), foldername, str(int(float(row.strip('\\n').split(\": \")[1]))) + '.csv')\n",
    "                    mw = int(float(row.strip('\\n').split(\": \")[1]))\n",
    "                except ValueError:\n",
    "                    print('ValueError: ', row)\n",
    "                    break\n",
    "                    \n",
    "#         if (not precursor_mz):\n",
    "#             if ('PrecursorMZ: ' in row):\n",
    "#                 precursor_mz = int(float(row.strip('\\n').split(\": \")[1]))\n",
    "        \n",
    "        if (not mw):\n",
    "            if ('MW: ' in row):\n",
    "                mw = int(float(row.strip('\\n').split(\": \")[1]))\n",
    "        \n",
    "                    \n",
    "        if ('Values and Intensities' in row):\n",
    "            \n",
    "        \n",
    "        # store the current element in string and dictionary data structure\n",
    "        string += row\n",
    "        if (': ' in row):\n",
    "            try:\n",
    "                [key, val] = row.strip('\\n').split(': ', 1)\n",
    "            except ValueError:\n",
    "                print('ValueError: ')\n",
    "                print(row)\n",
    "                print(row.strip('\\n').split(': '))\n",
    "            try:\n",
    "                if (key in item_dict.keys()):\n",
    "                    item_dict[key] = [item_dict[key]]\n",
    "                    item_dict[key].append(val)\n",
    "                    repeating_key = True\n",
    "                else:\n",
    "                    item_dict[key] = val\n",
    "            except IndexError:\n",
    "                print('Index error: ', item_dict)\n",
    "        else:\n",
    "            [ms, score] = row.strip('\\n').split(' ')\n",
    "            if ('MS' in item_dict.keys()):\n",
    "                item_dict['MS'].append(ms)\n",
    "            else:\n",
    "                item_dict['MS'] = [ms]\n",
    "            if ('Score' in item_dict.keys()):\n",
    "                item_dict['Score'].append(score)\n",
    "            else:\n",
    "                item_dict['Score'] = [score]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def df_check_precursorMZ_MS(df, output_df, problematic_df):\n",
    "#     precursorMZ = df.iloc[0]['PrecursorMZ']\n",
    "#     if (abs(precursorMZ - df.iloc[0]['MS']) >= 1):\n",
    "#         output_df = output_df.append(df.iloc[0], ignore_index=True)\n",
    "#     else:\n",
    "#         problematic_df = problematic_df.append(df.iloc[0], ignore_index=True) \n",
    "#     return output_df, problematic_df\n",
    "\n",
    "\n",
    "# def s_check_precursorMZ_MS2(series, output_df):\n",
    "#     precursorMZ = series['PrecursorMZ']\n",
    "#     if (type(precursorMZ) == list):\n",
    "#         precursorMZ = precursorMZ[0]\n",
    "#     if (abs(precursorMZ - series['MS2']) >= 1):\n",
    "#         output_df = output_df.append(series, ignore_index=True)\n",
    "#     return output_df\n",
    "    \n",
    "def clean_data(df, filename):\n",
    "    count = 0\n",
    "    # filter out rows with Score value < 10\n",
    "    #NIST how to set the score value <200\n",
    "    df = df[df['Score'] >= 200]\n",
    "    \n",
    "    # output_df is the processed (cleaned) DataFrame that will be returned\n",
    "    output_df = pd.DataFrame(columns=['Name', 'InChIKey', 'ExactMass','NIST#', 'Formula', 'MW', 'MS', 'Score','RI_estimated','RI_predicted'])    \n",
    "    \n",
    "      #NIST gc-ms data ms accuracy is low, not considering precursor and ms2 \n",
    "#     # problematic_df is the DataFrame that contains items with only one row and its PrecursorMZ is similar to its MS2\n",
    "#     problematic_df = pd.DataFrame(columns=['Name', 'InChIKey', 'ExactMass', 'Precursor_type', 'PrecursorMZ', 'MW', 'MS2', 'Score'])    \n",
    "        \n",
    "#     if (df.shape[0] < 2):\n",
    "#         # check for similar PrecursorMZ and MS2\n",
    "#         output_df, problematic_df = df_check_precursorMZ_MS2(df, output_df, problematic_df)\n",
    "            \n",
    "#         return output_df, problematic_df\n",
    "    \n",
    "    df = df.sort_values(by=['InChIKey', 'MS'], ascending=True)\n",
    "    \n",
    "    df_columns = ['Name', 'ExactMass', 'MW']\n",
    "    inchikeys = df['InChIKey'].unique().tolist()\n",
    "    \n",
    "    for inchikey in inchikeys:\n",
    "        working_df = df[df['InChIKey'] == inchikey]\n",
    "        \n",
    "#         if (working_df.shape[0] < 2):\n",
    "#             # check for similar PrecursorMZ and MS2\n",
    "#             output_df, problematic_df = df_check_precursorMZ_MS2(working_df, output_df, problematic_df)\n",
    "#             continue\n",
    "        \n",
    "        output_MS = working_df.iloc[0]['MS'] # to store the chosen MS(MS with the highest score is chosen)\n",
    "        output_MS_score = working_df.iloc[0]['Score'] # to store the chosen MS score\n",
    "        output_score = working_df.iloc[0]['Score'] # to store the accumulated score\n",
    "        retain_prev = False\n",
    "        \n",
    "        for i in range(1, working_df.shape[0]):\n",
    "            # update prev_row and curr_row\n",
    "            if not (retain_prev):\n",
    "                prev_row = working_df.iloc[i-1].copy()\n",
    "            curr_row = working_df.iloc[i]\n",
    "            curr_row_MS = curr_row['MS']\n",
    "            \n",
    "            # check if both MS2 should be group together by using the formula\n",
    "            # if they should be group together, we do the following:\n",
    "            # 1. add up the score\n",
    "            # 2. update output_MS2 to the one with the higher score\n",
    "            # 3. check for all other columns other than (InChIKey, MS2, Score),\n",
    "            #    if there are different values, we append them into list\n",
    "#             if ( (abs(output_MS2 - curr_row_MS2) * 1000000 / output_MS2) < 1000 ):\n",
    "#             if ( abs(output_MS - curr_row_MS) <= 0.7 ):\n",
    "            if (abs(output_MS - curr_row_MS) <=1):\n",
    "                retain_prev = True\n",
    "                output_score += curr_row['Score']\n",
    "                if (curr_row['Score'] > output_MS_score):\n",
    "                    output_MS_score = curr_row['Score']\n",
    "                    output_MS = curr_row_MS\n",
    "                for column in df_columns:\n",
    "                    if (type(prev_row[column]) == list):\n",
    "                        if (curr_row[column] not in prev_row[column]):\n",
    "                            prev_row[column].append(curr_row[column])\n",
    "                    elif (prev_row[column] != curr_row[column]):\n",
    "                        prev_row[column] = [prev_row[column]]\n",
    "                        prev_row[column].append(curr_row[column])\n",
    "                        \n",
    "            # if they shouldn't be group together, we update the MS2 and Score\n",
    "            # to the chosen MS2 (output_MS2) and accumulated score (output_score)\n",
    "            # and append the series to output_df\n",
    "            else:\n",
    "                retain_prev = False\n",
    "                prev_row['MS'] = output_MS\n",
    "                prev_row['Score'] = output_score\n",
    "                \n",
    "                # check for similar PrecursorMZ and MS2\n",
    "                output_df = s_check_precursorMZ_MS(prev_row, output_df)\n",
    "                output_MS2 = curr_row['MS']\n",
    "                output_MS2_score = curr_row['Score']\n",
    "                output_score = curr_row['Score']\n",
    "\n",
    "        # handling the last row\n",
    "        if (retain_prev):\n",
    "            prev_row['MS'] = output_MS\n",
    "            prev_row['Score'] = output_score\n",
    "            \n",
    "#             # check for similar PrecursorMZ and MS2\n",
    "#             output_df = s_check_precursorMZ_MS(prev_row, output_df)\n",
    "#         else:\n",
    "#             # check for similar PrecursorMZ and MS2\n",
    "#             output_df = s_check_precursorMZ_MS(curr_row, output_df)\n",
    "\n",
    "    output_df.sort_values(by=['InChIKey', 'Score'], ascending=False, inplace=True)\n",
    "#     return output_df, problematic_df\n",
    "    return output_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
