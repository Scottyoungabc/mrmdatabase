{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Please ensure that this script is in the same directory as the text file (Mona_experimental_ms.txt)\n",
    "Run the following code block in sequence, some code block might take up to half an hour (depending on computer speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm  #instant showing the progress of loops \n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\jupyter_workspace\\\\datacleaning\\\\GC-MS'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\n",
    "    'Name:', \n",
    "    'Formula:',\n",
    "    'MW:',\n",
    "    'NIST#:',\n",
    "    'InChIKey:', \n",
    "    'MS2:',\n",
    "    'Score:',\n",
    "    'EstRI', #try to extract the 2 RI values in the text\n",
    "    'PredRI',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_filename = 'GCMS-NIST20-example.txt' # name of the raw data text file\n",
    "foldername = 'GCMS_output' # this is the folder that we are going to store our cleaned data\n",
    "cleaned_folder_name = 'cleaned_data'\n",
    "problematic_folder_name = 'problematic_data'\n",
    "ignore = False # variable used to determine whether to exclude the element\n",
    "file_exist = True # variable used to determine whether the file that we are going to append exist or not\n",
    "repeating_key = False # variable used to determine whether there are multiple fields with same name in the element\n",
    "item_dict = {} # dictionary to store all the fields and value for an element\n",
    "string = '' # element in string form that are going to be written into error.txt when we can't decide its filename\n",
    "filename = '' # name of the file to store the cleaned data\n",
    "inchikey, mw= '','' # these variables are used to determine whether to include or exclude the element\n",
    "ms2=[]\n",
    "score=[]\n",
    "msscore=[]\n",
    "\n",
    "#trial on the ri index\n",
    "PredRI = False #ri variable determine whether include AIri\n",
    "EstRI = False # ri variable determine whether include Estri\n",
    "\n",
    "if not (os.path.exists(foldername)):\n",
    "    os.makedirs(foldername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formula: C6H16O4P2S\n",
      "\n",
      "MW: 246 Exact Mass: 246.024453 NIST#: 383781 ID#: 220826 DB: mainlib\n",
      "\n",
      "InChIKey: DNSXYZRDXBWQEH-UHFFFAOYSA-N   Non-stereo\n",
      "\n",
      "Value: 1462 iu\n",
      "\n",
      "['PredRI', '1462']\n",
      "Formula: C10H6ClNO2\n",
      "\n",
      "MW: 207 Exact Mass: 207.008706 CAS#: 2797-51-5 NIST#: 135389 ID#: 200731 DB: mainlib\n",
      "\n",
      "InChIKey: OBLNWSCLAYSJJR-UHFFFAOYSA-N   Non-stereo\n",
      "\n",
      "Value: 1891 iu\n",
      "\n",
      "['EstRI', '1891']\n",
      "Value: 2011 iu\n",
      "\n",
      "['PredRI', '2011']\n",
      "Formula: C10H6ClNO2\n",
      "\n",
      "MW: 207 Exact Mass: 207.008706 CAS#: 2797-51-5 NIST#: 135389 ID#: 200731 DB: mainlib\n",
      "\n",
      "InChIKey: OBLNWSCLAYSJJR-UHFFFAOYSA-N   Non-stereo\n",
      "\n",
      "Value: 1891 iu\n",
      "\n",
      "['EstRI', '1891']\n",
      "Value: 2011 iu\n",
      "\n",
      "['PredRI', '2011']\n",
      "Formula: C10H6ClNO2\n",
      "\n",
      "MW: 207 Exact Mass: 207.008706 CAS#: 2797-51-5 NIST#: 135389 ID#: 200731 DB: mainlib\n",
      "\n",
      "InChIKey: OBLNWSCLAYSJJR-UHFFFAOYSA-N   Non-stereo\n",
      "\n",
      "Value: 1891 iu\n",
      "\n",
      "['EstRI', '1891']\n",
      "Value: 2011 iu\n",
      "\n",
      "['PredRI', '2011']\n",
      "Formula: C11H14O3\n",
      "\n",
      "MW: 194 Exact Mass: 194.094295 CAS#: 122-48-5 NIST#: 8502 ID#: 154129 DB: mainlib\n",
      "\n",
      "InChIKey: OJYLAHXKWMRDGS-UHFFFAOYSA-N   Non-stereo\n",
      "\n",
      "Value: 1638 iu\n",
      "\n",
      "['EstRI', '1638']\n",
      "Value: 1654 iu\n",
      "\n",
      "['PredRI', '1654']\n",
      "Formula: C14H19NO\n",
      "\n",
      "MW: 217 Exact Mass: 217.146665 NIST#: 403046 ID#: 232894 DB: mainlib\n",
      "\n",
      "InChIKey: VWFLHUSSSXMNIF-UHFFFAOYSA-N   Non-stereo\n",
      "\n",
      "Value: 1677 iu\n",
      "\n",
      "['EstRI', '1677']\n",
      "Value: 1619 iu\n",
      "\n",
      "['PredRI', '1619']\n"
     ]
    }
   ],
   "source": [
    "### This code block might take around 8 minutes to run\n",
    "with open(txt_filename, mode='r', encoding='utf-8-sig') as readf:\n",
    "    while True:\n",
    "        row = readf.readline()\n",
    "\n",
    "        if ('Name: 'in row or row ==''):\n",
    "#             readf.readline()\n",
    "\n",
    "            if not (ignore):\n",
    "                # if there are multiple fields with same name in the current element,\n",
    "                # we output them into repeating_key.csv for further debugging purpose\n",
    "                if (repeating_key):\n",
    "                    filename = os.path.join(os.getcwd(), 'repeating_key.csv')\n",
    "\n",
    "                if (filename):\n",
    "\n",
    "                    file_exist = os.path.isfile(filename)\n",
    "\n",
    "                    with open(filename, 'a', encoding='utf-8-sig', newline='') as writef:\n",
    "                        writer = csv.writer(writef)\n",
    "                        if not (file_exist):\n",
    "                            writer.writerow(header)\n",
    "                        \n",
    "                        ms2 = item_dict['MS2:']\n",
    "                        score = item_dict['Score:']\n",
    "                        while (len(ms2) > 0):\n",
    "                            item_dict['MS2:'] = ms2.pop(0)\n",
    "                            item_dict['Score:'] = score.pop(0)\n",
    "                            writer.writerow(item_dict.get(col, '') for col in header)\n",
    "\n",
    "                else:\n",
    "                    # Will generate error.txt when:\n",
    "                    # 2. There is trailing space or newline at the end of the file\n",
    "                    with open('error.txt', 'a', encoding='utf-8-sig') as writef:\n",
    "                        writef.write(string)\n",
    "                        writef.write('\\n')\n",
    "                    \n",
    "            # reinitialize everything after writing an item into a file\n",
    "            ignore = False\n",
    "            file_exist = True\n",
    "            repeating_key = False\n",
    "            item_dict = {}\n",
    "            string = ''\n",
    "            filename = ''\n",
    "            ms2=[]\n",
    "            score=[]\n",
    "            msscore=[]\n",
    "            EstRI = False\n",
    "            PredRI = False\n",
    "            \n",
    "            if (row ==''):\n",
    "                break # break out of the loop when we reach EOF\n",
    "#             else:\n",
    "#                 row = readf.readline()             \n",
    "           \n",
    "        # store the current element in string and dictionary data structure\n",
    "        if('Name' in row):\n",
    "            try:\n",
    "                [key,val] = row.strip('\\n').split(' ',1)\n",
    "            except ValueError:\n",
    "                print('ValueError: ')\n",
    "                print(row)\n",
    "                print(row.strip('\\n').split(': '))\n",
    "            try:\n",
    "                if (key in item_dict.keys()):\n",
    "                    item_dict[key] = [item_dict[key]]\n",
    "                    item_dict[key].append(val)\n",
    "                    repeating_key = True\n",
    "                else:\n",
    "                    item_dict[key] = val\n",
    "            except IndexError:\n",
    "                print('Index error: ', item_dict)\n",
    "\n",
    "        if('Formula' in row):\n",
    "            print(row)\n",
    "            try:\n",
    "                [key,val] = row.strip('\\n').split(' ',1)\n",
    "            except ValueError:\n",
    "                print('ValueError: ')\n",
    "                print(row)\n",
    "                print(row.strip('\\n').split(': '))\n",
    "            try:\n",
    "                if (key in item_dict.keys()):\n",
    "                    item_dict[key] = [item_dict[key]]\n",
    "                    item_dict[key].append(val)\n",
    "                    repeating_key = True\n",
    "                else:\n",
    "                    item_dict[key] = val\n",
    "            except IndexError:\n",
    "                print('Index error: ', item_dict)\n",
    "\n",
    "        if('MW: ' in row):\n",
    "            print(row)\n",
    "            try:\n",
    "                [key,val] = row.strip('\\n').split(' ')[0:2]\n",
    "#                 print([key,val])\n",
    "            except ValueError:\n",
    "                print('ValueError: ')\n",
    "                print(row)\n",
    "                print(row.strip('\\n').split(': '))\n",
    "            try:\n",
    "                if (key in item_dict.keys()):\n",
    "                    item_dict[key] = [item_dict[key]]\n",
    "                    item_dict[key].append(val)\n",
    "                    repeating_key = True\n",
    "                else:\n",
    "                    item_dict[key] = val\n",
    "            except IndexError:\n",
    "                print('Index error: ', item_dict)\n",
    "\n",
    "        if ('NIST#: ' in row):\n",
    "            try:\n",
    "                [key,val] = row.strip('\\n').split(' ')[-6:-4]\n",
    "#                 print([key,val])\n",
    "            except ValueError:\n",
    "                print('ValueError: ')\n",
    "                print(row)\n",
    "                print(row.strip('\\n').split(': '))\n",
    "            try:\n",
    "                if (key in item_dict.keys()):\n",
    "                    item_dict[key] = [item_dict[key]]\n",
    "                    item_dict[key].append(val)\n",
    "                    repeating_key = True\n",
    "                else:\n",
    "                    item_dict[key] = val\n",
    "            except IndexError:\n",
    "                print('Idex error: ', item_dict)\n",
    "                \n",
    "        if('InChIKey: ' in row):\n",
    "            print(row)\n",
    "            try:\n",
    "                [key,val] = row.strip('\\n').split(' ')[0:2]\n",
    "#                 print([key,val])\n",
    "            except ValueError:\n",
    "                print('ValueError: ')\n",
    "                print(row)\n",
    "                print(row.strip('\\n').split(': '))\n",
    "            try:\n",
    "                if (key in item_dict.keys()):\n",
    "                    item_dict[key] = [item_dict[key]]\n",
    "                    item_dict[key].append(val)\n",
    "                    repeating_key = True\n",
    "                else:\n",
    "                    item_dict[key] = val\n",
    "            except IndexError:\n",
    "                print('Index error: ', item_dict)\n",
    "        \n",
    "        if('|' in row):  \n",
    "            ms2=[]\n",
    "            score=[]\n",
    "            msscore=row.strip('\\n\\t')\n",
    "            msscore=msscore.strip('')\n",
    "            msscore2 = msscore.replace('\\t',' ')\n",
    "            msscore3 = msscore2.replace('|', '')\n",
    "            msscore4 = msscore3.split(' ')\n",
    "            msscore4 = [a for a in msscore4 if not a=='']\n",
    "            for i in range(len(msscore4)):\n",
    "                a=msscore4[i]\n",
    "                if i%2==0:\n",
    "                    ms2.append(a)\n",
    "                else:\n",
    "                    score.append(a) \n",
    "            if('MS2:' in item_dict.keys()):\n",
    "                for item in ms2:\n",
    "                    item_dict['MS2:'].append(item) \n",
    "            else:\n",
    "                item_dict['MS2:']= ms2\n",
    "            if('Score:' in item_dict.keys()):\n",
    "                for item in score:\n",
    "                    item_dict['Score:'].append(item)\n",
    "            else:\n",
    "                item_dict['Score:'] = score\n",
    "#         print(item_dict)\n",
    "\n",
    "        #extract the estimated RI and predicted RI\n",
    "        if('Estimated non-polar retention index ' in row):\n",
    "            EstRI = True\n",
    "            continue\n",
    "        \n",
    "        if('Value:' in row):\n",
    "            rowstart = row.strip('\\n').split(' ')[0]\n",
    "            if (rowstart =='Value:') & EstRI:\n",
    "                print(row)\n",
    "                #modified the key\n",
    "                try:\n",
    "                    riid = 'EstRI' \n",
    "                    rivalue = row.strip('\\n').split(' ')[1]\n",
    "                    [key,val] = [riid,rivalue]\n",
    "#                     [key,val] = row.strip('\\n').split(' ')[0:2]\n",
    "                    print([key,val])\n",
    "                except ValueError:\n",
    "                    print('ValueError: ')\n",
    "                    print(row)\n",
    "                    print(row.strip('\\n').split(': '))\n",
    "                try:\n",
    "                    if (key in item_dict.keys()):\n",
    "                        item_dict[key] = [item_dict[key]]\n",
    "                        item_dict[key].append(val)\n",
    "                        repeating_key = True\n",
    "                    else:\n",
    "                        item_dict[key] = val\n",
    "                except IndexError:\n",
    "                    print('Index error: ', item_dict)\n",
    "                EstRI = False\n",
    "#             else:\n",
    "#                 continue\n",
    "    \n",
    "        \n",
    "        if('AI predicted non-polar retention index' in row):\n",
    "            PredRI = True\n",
    "            continue\n",
    "        \n",
    "        if('Value:' in row):\n",
    "            rowstart = row.strip('\\n').split(' ')[0]\n",
    "            if (rowstart =='Value:') & PredRI:\n",
    "                print(row)\n",
    "                #modified the key\n",
    "                try:\n",
    "                    riid = 'PredRI' \n",
    "                    rivalue = row.strip('\\n').split(' ')[1]\n",
    "                    [key,val] = [riid,rivalue]\n",
    "#                     [key,val] = row.strip('\\n').split(' ')[0:2]\n",
    "                    print([key,val])\n",
    "                except ValueError:\n",
    "                    print('ValueError: ')\n",
    "                    print(row)\n",
    "                    print(row.strip('\\n').split(': '))\n",
    "                try:\n",
    "                    if (key in item_dict.keys()):\n",
    "                        item_dict[key] = [item_dict[key]]\n",
    "                        item_dict[key].append(val)\n",
    "                        repeating_key = True\n",
    "                    else:\n",
    "                        item_dict[key] = val\n",
    "                except IndexError:\n",
    "                    print('Index error: ', item_dict)   \n",
    "                PredRI = False\n",
    "#             else:\n",
    "#                 continue\n",
    "            \n",
    "        # exclude these fields\n",
    "#         if ('Synon: ' in row or 'Comments: ' in row or 'Num Peaks: ' in row):\n",
    "        if ('Contributor:' in row or 'Other DBs:'in row or'Synonyms: ' in row):\n",
    "            continue\n",
    "        if ('Values and Intensities: ' in row or'Confidence interval:'in row or 'Column Type:'in row):\n",
    "            continue\n",
    "\n",
    "       #determine the filename:\n",
    "        if (not filename):\n",
    "            if ('MW: ' in row):\n",
    "                try:\n",
    "                    filename = os.path.join(os.getcwd(), foldername, str(int(float(row.strip('\\n').split(' ')[1]))) + '.csv')\n",
    "                    mw = int(float(row.strip('\\n').split(\" \")[1]))\n",
    "                except ValueError:\n",
    "                    print('ValueError: ', row)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting part finised. to the data cleanup and minning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define clean_data function to filter ms peaks with low abundance\n",
    "#ms peak abundance minimum value 30\n",
    "\n",
    "def clean_data(df, filename):\n",
    "    # filter out rows with Score value < 30\n",
    "    #NIST how to set the score value <30\n",
    "    df = df[df['Score:'] >= 30]\n",
    "    print('cleandata:', df.shape)#try to trouble shoot\n",
    "    \n",
    "    # output_df is the processed (cleaned) DataFrame that will be returned\n",
    "    output_df = pd.DataFrame(columns=['Name:', 'Formula:', 'MW:', 'NIST#:', 'InChIKey:', 'MS2:', 'Score:','EstRI','PredRI'])    \n",
    "    \n",
    "    #sort inchikey to get the same compounds, sort ms2 to get ms2 for the same compounds\n",
    "    df = df.sort_values(by=['InChIKey:', 'MS2:'], ascending=True)\n",
    "    \n",
    "    df_columns = ['Name:', 'Formula:', 'MW:', 'NIST#:']  \n",
    "    inchikeys = df['InChIKey:'].unique().tolist()\n",
    "    \n",
    "    for inchikey in inchikeys:\n",
    "        working_df = df[df['InChIKey:'] == inchikey]\n",
    "        \n",
    "#         if (working_df.shape[0] < 2):\n",
    "#             # check for similar PrecursorMZ and MS2\n",
    "#             output_df, problematic_df = df_check_precursorMZ_MS2(working_df, output_df, problematic_df)\n",
    "#             continue\n",
    "        \n",
    "        output_MS = working_df.iloc[0]['MS2:'] # to store the chosen MS(MS with the highest score is chosen)\n",
    "        output_MS_score = working_df.iloc[0]['Score:'] # to store the chosen MS score\n",
    "        output_score = working_df.iloc[0]['Score:'] # to store the accumulated score\n",
    "        retain_prev = False\n",
    "        \n",
    "        for i in range(1, working_df.shape[0]):\n",
    "            # update prev_row and curr_row\n",
    "            if not (retain_prev):\n",
    "                prev_row = working_df.iloc[i-1].copy()\n",
    "            curr_row = working_df.iloc[i]\n",
    "            curr_row_MS = curr_row['MS2:']\n",
    "            \n",
    "            # check if both MS2 should be group together by using the formula\n",
    "            # if they should be group together, we do the following:\n",
    "            # 1. add up the score\n",
    "            # 2. update output_MS2 to the one with the higher score\n",
    "            # 3. check for all other columns other than (InChIKey, MS2, Score),\n",
    "            if (abs(output_MS - curr_row_MS) <=1):\n",
    "                retain_prev = True\n",
    "                output_score += curr_row['Score:']\n",
    "                if (curr_row['Score:'] > output_MS_score):\n",
    "                    output_MS_score = curr_row['Score:']\n",
    "                    output_MS = curr_row_MS\n",
    "                for column in df_columns:\n",
    "                    if (type(prev_row[column]) == list):\n",
    "                        if (curr_row[column] not in prev_row[column]):\n",
    "                            prev_row[column].append(curr_row[column])\n",
    "                    elif (prev_row[column] != curr_row[column]):\n",
    "                        prev_row[column] = [prev_row[column]]\n",
    "                        prev_row[column].append(curr_row[column])\n",
    "                        \n",
    "            # if they shouldn't be group together, we update the MS2 and Score\n",
    "            # to the chosen MS2 (output_MS2) and accumulated score (output_score)\n",
    "            # and append the series to output_df\n",
    "            else:\n",
    "                retain_prev = False\n",
    "                prev_row['MS2:'] = output_MS\n",
    "                prev_row['Score:'] = output_score\n",
    "                \n",
    "                # check for similar PrecursorMZ and MS2\n",
    "                output_df = output_df.append(prev_row, ignore_index=True)\n",
    "#                 output_df = s_check_precursorMZ_MS(prev_row, output_df)\n",
    "                output_MS2 = curr_row['MS2:']\n",
    "                output_MS2_score = curr_row['Score:']\n",
    "                output_score = curr_row['Score:']\n",
    "\n",
    "        # handling the last row\n",
    "        if (retain_prev):\n",
    "            prev_row['MS2:'] = output_MS\n",
    "            prev_row['Score:'] = output_score\n",
    "            \n",
    "            output_df = output_df.append(prev_row, ignore_index=True)\n",
    "#             # check for similar PrecursorMZ and MS2\n",
    "#             output_df = s_check_precursorMZ_MS(prev_row, output_df)\n",
    "        else:\n",
    "            output_df = output_df.append(curr_row, ignore_index=True)\n",
    "#             # check for similar PrecursorMZ and MS2\n",
    "#             output_df = s_check_precursorMZ_MS(curr_row, output_df)\n",
    "\n",
    "    output_df.sort_values(by=['InChIKey:', 'Score:'], ascending=False, inplace=True)\n",
    "#     return output_df, problematic_df\n",
    "    print('outputdim:', output_df.shape)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 25.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleandata: (20, 9)\n",
      "outputdim: (1, 9)\n",
      "cleandata: (138, 9)\n",
      "outputdim: (1, 9)\n",
      "cleandata: (55, 9)\n",
      "outputdim: (1, 9)\n",
      "cleandata: (46, 9)\n",
      "outputdim: (1, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#cleaning sorted data and prepare for the algorithm calculation\n",
    "read_folder = os.path.join(os.getcwd(), foldername)  #folder that we will read data from\n",
    "cleaned_folder = os.path.join(read_folder, 'cleaned_data') #folder to store cleaned data\n",
    "\n",
    "if not (os.path.exists(cleaned_folder)):\n",
    "    os.makedirs(cleaned_folder)\n",
    "\n",
    "# get list of csv file names\n",
    "cwd = os.getcwd()\n",
    "os.chdir(read_folder)\n",
    "listdir = glob.glob('*.csv')\n",
    "os.chdir(cwd)\n",
    "\n",
    "#for filename in listdir\n",
    "for filename in tqdm(listdir):\n",
    "    output_filename=os.path.join(cleaned_folder, filename.strip('.csv')+'_cleaned.csv')\n",
    "    readf = os.path.join(read_folder, filename)\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(readf)\n",
    "    except OSError:\n",
    "        print(readf)\n",
    "    \n",
    "#     df = df[['Name:', 'Formula:', 'MW:', 'NIST#:', 'InChIKey:', 'MS2:', 'Score:', 'EstRI' , 'PredRI']]\n",
    "    df= clean_data(df,filename)\n",
    "    \n",
    "    if (df.shape[0]>0):\n",
    "        df.to_csv(output_filename, header=True, mode='a', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
