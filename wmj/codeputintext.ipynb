{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loading modules \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "%matplotlib inline\n",
    "\n",
    "from pprint import pprint\n",
    "from rdkit import Chem\n",
    "from mordred import Calculator, descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.EState import Fingerprinter\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.rdmolops import RDKFingerprint\n",
    "from rdkit.Chem.AtomPairs.Sheridan import GetBPFingerprint\n",
    "from rdkit.Chem.EState.Fingerprinter import FingerprintMol\n",
    "from rdkit.Avalon.pyAvalonTools import GetAvalonFP #GetAvalonCountFP  #int vector version\n",
    "from rdkit.Chem.AllChem import  GetMorganFingerprintAsBitVect, GetErGFingerprint,GetHashedAtomPairFingerprintAsBitVect,GetHashedTopologicalTorsionFingerprintAsBitVect\n",
    "from rdkit.DataStructs.cDataStructs import ConvertToNumpyArray\n",
    "import rdkit.DataStructs.cDataStructs\n",
    "\n",
    "#loading data\n",
    "directory = 'D:/jupyter_workspace/wmj'\n",
    "# paperdat = pd.read_csv(\"2014acdata.csv\"),  ##remove EC50 value larger than 500 in wmj_smiles2\n",
    "filename = 'wmj_smiles2.csv'\n",
    "data = pd.read_csv(os.path.join(directory,filename))\n",
    "\n",
    "#define labels and the variables\n",
    "###good smiles check ahead of every mds calculation,check the smiles is good canonical smiles \n",
    "smi = mydat['smiles']\n",
    "goodsmi =[]\n",
    "for a in smi:\n",
    "    try:\n",
    "        b = Chem.CanonSmiles(a)\n",
    "        goodsmi.append(b)\n",
    "    except:\n",
    "        print('Invalid SMILES:',b)\n",
    "# goodsmi\n",
    "print('no bad smiles\\n')\n",
    "\n",
    "data['Mol'] = data['smiles'].apply(Chem.MolFromSmiles)\n",
    "num_mols = len(data)\n",
    "\n",
    "#Create X and y\n",
    "#Convert to Numpy arrays\n",
    "y = data['category'].values\n",
    "\n",
    "\n",
    "def ExplicitBitVect_to_NumpyArray(bitvector):\n",
    "    bitstring = bitvector.ToBitString()\n",
    "    intmap = map(int, bitstring)\n",
    "    return np.array(list(intmap))\n",
    "\n",
    "\n",
    "class fingerprint():\n",
    "    def __init__(self, fp_fun, name):\n",
    "        self.fp_fun = fp_fun\n",
    "        self.name = name\n",
    "        self.x = []\n",
    "\n",
    "    def apply_fp(self, mols):\n",
    "        for mol in mols:\n",
    "            fp = self.fp_fun(mol)\n",
    "            if isinstance(fp, tuple):\n",
    "                fp = np.array(list(fp[0]))\n",
    "            if isinstance(fp, rdkit.DataStructs.cDataStructs.ExplicitBitVect):\n",
    "                fp = ExplicitBitVect_to_NumpyArray(fp)\n",
    "            if isinstance(fp,rdkit.DataStructs.cDataStructs.IntSparseIntVect):\n",
    "                fp = np.array(list(fp))\n",
    "\n",
    "            self.x += [fp]\n",
    "\n",
    "            if (str(type(self.x[0])) != \"<class 'numpy.ndarray'>\"):\n",
    "                print(\"WARNING: type for \", self.name, \"is \", type(self.x[0]))\n",
    "\n",
    "def make_fingerprints(length = 512, verbose=False):\n",
    "    fp_list = [\n",
    "         #fingerprint(lambda x : GetBPFingerprint(x, fpfn=AtomPair), \n",
    "         #            \"Physiochemical properties (1996)\"), ##NOTE: takes a long time to compute\n",
    "         fingerprint(lambda x : GetHashedAtomPairFingerprintAsBitVect(x, nBits = length),\n",
    "                    \" Atom pair (1985)\"),\n",
    "         fingerprint(lambda x : GetHashedTopologicalTorsionFingerprintAsBitVect(x, nBits = length),\n",
    "                     \"Topological torsion (1987)\"),\n",
    "         fingerprint(lambda x : GetMorganFingerprintAsBitVect(x, 2, nBits = length),\n",
    "                     \"Morgan circular \"),\n",
    "         fingerprint(FingerprintMol, \"Estate (1995)\"),\n",
    "         fingerprint(lambda x: GetAvalonFP(x, nBits=length),\n",
    "                    \"Avalon bit based (2006)\"),\n",
    "         fingerprint(lambda x: np.append(GetAvalonFP(x, nBits=length), Descriptors.MolWt(x)),\n",
    "                    \"Avalon+mol. weight\"),\n",
    "         fingerprint(lambda x: GetErGFingerprint(x), \"ErG fingerprint (2006)\"),\n",
    "         fingerprint(lambda x : RDKFingerprint(x, fpSize=length),\n",
    "                     \"RDKit fingerprint\")\n",
    "    ]\n",
    "\n",
    "    for fp in fp_list:\n",
    "        if (verbose): print(\"doing\", fp.name)\n",
    "        fp.apply_fp(list(data['Mol']))\n",
    "\n",
    "    return fp_list\n",
    "\n",
    "fp_list = make_fingerprints()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def test_model_cv(model, x, y, cv=10):\n",
    "    scores = cross_val_score(model, x, y, cv=cv, n_jobs=-1, \n",
    "scoring='accuracy')\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "def test_fingerprints(fp_list, model, y, verbose = True):\n",
    "\n",
    "    fingerprint_scores = {}\n",
    "\n",
    "    for fp in fp_list:\n",
    "        if verbose: print(\"doing \", fp.name)\n",
    "        fingerprint_scores[fp.name] = test_model_cv(model, fp.x, y)\n",
    "\n",
    "    sorted_names = sorted(fingerprint_scores, key=fingerprint_scores.__getitem__, reverse=False)\n",
    "\n",
    "    print(\"\\\\begin{tabular}{c c}\")\n",
    "    print(\"           name        &  avg accuracy in CV \\\\\\\\\")\n",
    "    print(\"\\\\hline\")\n",
    "    for i in range(len(sorted_names)):\n",
    "        name = sorted_names[i]\n",
    "        print(\"%30s & %5.3f \\\\\\\\\" % (name, fingerprint_scores[name]))\n",
    "    print(\"\\\\end{tabular}\")\n",
    "\n",
    "    \n",
    "model=RandomForestClassifier(n_estimators=200, max_depth=3,\n",
    "                          random_state=0)\n",
    "test_fingerprints(fp_list,model, y, verbose=True)\n",
    "\n",
    "##load variables and lables and split data\n",
    "features = fp_list[1].x\n",
    "labels = np.array(y)\n",
    "X_train, X_test, y_train, y_test ,indices_train, indices_test= train_test_split(features, labels, data.index,test_size=0.3, \n",
    "                                                                                 random_state=1)\n",
    "\n",
    "##setup multiple models and comparing performance\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models=[\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3,\n",
    "                          random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "CV=5\n",
    "cv_df = pd.DataFrame(index=range(CV*len(models)))\n",
    "entris=[]\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, features, labels,\n",
    "                                scoring = 'accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name,fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries,columns=['model_name','fold_idx',\n",
    "                                         'accuracy'])\n",
    "import seaborn as sns\n",
    "fg=sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "fg=sns.stripplot(x='model_name', y = 'accuracy', data=cv_df,\n",
    "             size=8, jitter=True, edgecolor='gray', linewidth=2)\n",
    "# plt.show()\n",
    "xlabel=cv_df['model_name']\n",
    "fg.set_xticklabels(xlabel, rotation=45)\n",
    "fg.figure.savefig('classifiercompare.png',bbox_inches='tight')\n",
    "\n",
    "cv_df.groupby('model_name').accuracy.mean()\n",
    "\n",
    "###select LineaerSVC classifier\n",
    "#use LinearSVC for modeling\n",
    "model = LinearSVC()\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, data.index, test_size=0.33, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "plot_confusion_matrix(model,X_test,y_test)\n",
    "\n",
    "#print classification performance\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,y_pred,\n",
    "                target_names=['class1','class2','class3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
