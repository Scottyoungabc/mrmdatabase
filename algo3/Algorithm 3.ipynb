{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environstd_inchi.csv\n"
     ]
    }
   ],
   "source": [
    "algo_3_output_folder = 'algorithm_3_output'\n",
    "retrieved_filename = 'retrieved_result.csv'\n",
    "extraction_keys_filename = 'environstd_inchi.csv'\n",
    "extraction_keys_file_encoding = 'ANSI'\n",
    "\n",
    "foldername = 'Mona_experimental_ms' # this is the folder where the cleaned data is stored\n",
    "cleaned_folder_name = 'cleaned_data'\n",
    "\n",
    "read_folder = os.path.join(os.getcwd(), foldername)\n",
    "cleaned_folder = os.path.join(read_folder, cleaned_folder_name) # folder that we will be reading data from\n",
    "\n",
    "df = pd.read_csv(os.path.join(os.getcwd(), extraction_keys_filename), encoding=extraction_keys_file_encoding)\n",
    "inchikey_list = df['Inchikey'].str.strip().array\n",
    "name_list = df['Name'].str.strip().array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1046/1046 [25:35<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# algorithm 3\n",
    "\n",
    "### this code block might take around 25 minutes to run\n",
    "\n",
    "def clean_precursormz(df):\n",
    "    inchikeys = df['InChIKey'].unique().tolist()\n",
    "    for inchikey in inchikeys:\n",
    "        curr_precursormz = df.loc[df['InChIKey'] == inchikey, 'PrecursorMZ'].iloc[0]\n",
    "        try:\n",
    "            curr_precursormz = ast.literal_eval(curr_precursormz)\n",
    "            df.loc[df['InChIKey'] == inchikey, ['PrecursorMZ']] = curr_precursormz[0]\n",
    "        except TypeError:\n",
    "            curr_precursormz = float(curr_precursormz)\n",
    "            df.loc[df['InChIKey'] == inchikey, ['PrecursorMZ']] = curr_precursormz\n",
    "        except ValueError:\n",
    "            curr_precursormz = float(curr_precursormz)\n",
    "            df.loc[df['InChIKey'] == inchikey, ['PrecursorMZ']] = curr_precursormz\n",
    "    return df\n",
    "\n",
    "\n",
    "def retrieve_ms2_dict(df):\n",
    "    ms2_dict = pd.Series(df['Score'].array, index=df['MS2']).to_dict()\n",
    "    return ms2_dict\n",
    "\n",
    "def append_to_list(df):\n",
    "    output_dict = {}\n",
    "    for i, item in df['Name'].items():\n",
    "        if 'Name' in output_dict.keys():\n",
    "            if item not in output_dict['Name']:\n",
    "                if type(output_dict['Name']) == list:\n",
    "                    if type(item) == list:\n",
    "                        output_dict['Name'] += item\n",
    "                    else:\n",
    "                        output_dict['Name'].append(item)\n",
    "                else:\n",
    "                    if type(item) == list:\n",
    "                        output_dict['Name'] = item.append(output_dict['Name'])\n",
    "                    else:\n",
    "                        output_dict['Name'] = [output_dict['Name'], item]\n",
    "        else:\n",
    "            output_dict['Name'] = item\n",
    "    return pd.Series(output_dict)\n",
    "\n",
    "search_range = 0.7\n",
    "output_folder = os.path.join(os.getcwd(), algo_3_output_folder, 'non_combined_output')\n",
    "\n",
    "if not (os.path.exists(output_folder)):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "## get list of csv file names\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cleaned_folder)\n",
    "listdir = glob.glob('*.csv')\n",
    "os.chdir(cwd)\n",
    "\n",
    "for filename in tqdm(listdir):\n",
    "#     if filename == '74_cleaned.csv':\n",
    "        readf = os.path.join(cleaned_folder, filename)\n",
    "        precursormz = int(filename.split('_')[0])\n",
    "        interfering_file = os.path.join(cleaned_folder, str(precursormz - 1) + '_cleaned.csv')\n",
    "        df = pd.read_csv(readf)\n",
    "        df.sort_values(by=['InChIKey', 'MS2'], inplace=True)\n",
    "        df = clean_precursormz(df)\n",
    "\n",
    "        try:\n",
    "            df2 = pd.read_csv(interfering_file)\n",
    "        except FileNotFoundError:\n",
    "            df2 = pd.DataFrame()\n",
    "\n",
    "        output_file = os.path.join(output_folder, str(precursormz) + '_algo4.csv')\n",
    "        inchikeys = df['InChIKey'].unique().tolist()\n",
    "        TP, FN = 1, 0\n",
    "        header_flag = True\n",
    "\n",
    "        for inchikey in inchikeys:\n",
    "            target_item_df = df[df['InChIKey'] == inchikey].copy()\n",
    "            curr_precursormz = target_item_df.iloc[0]['PrecursorMZ']\n",
    "            \n",
    "            interfering_items_df = df[df['InChIKey'] != inchikey]\n",
    "            interfering_items_df = interfering_items_df.append(df2, ignore_index=True)\n",
    "            interfering_items_df = clean_precursormz(interfering_items_df)\n",
    "            interfering_items_df = interfering_items_df[interfering_items_df['PrecursorMZ'] >= (curr_precursormz - 0.7)]\n",
    "            \n",
    "            if interfering_items_df.shape[0] < 1:\n",
    "                target_item_df.to_csv(output_file, index=False)\n",
    "                break\n",
    "                \n",
    "            interfering_items_df.sort_values(by=['InChIKey', 'MS2'], inplace=True)\n",
    "            interfering_items_s = interfering_items_df.groupby(['InChIKey']).apply(retrieve_ms2_dict)\n",
    "\n",
    "            target_ms2_array = target_item_df['MS2'].array\n",
    "            output_dict = {}\n",
    "            \n",
    "            for ms2 in target_ms2_array:\n",
    "                FP, TN = 0, 0\n",
    "                for i, ms2_dict in interfering_items_s.iteritems():\n",
    "                    TN_flag = True\n",
    "                    \n",
    "                    if (ms2 - max(ms2_dict.keys())) > 0.7:\n",
    "                        TN += 1\n",
    "                        continue\n",
    "                        \n",
    "                    for key in ms2_dict.keys():\n",
    "                        diff = round(ms2 - key, 2)\n",
    "                        if abs(diff) <= search_range:\n",
    "                            TN_flag = False\n",
    "                            FP += 1\n",
    "                        elif diff < 0:\n",
    "                            if (TN_flag):\n",
    "                                TN += 1\n",
    "                            break\n",
    "                \n",
    "                output_dict[ms2] = {\n",
    "                    'TP': TP,\n",
    "                    'FN': FN,\n",
    "                    'TN': TN,\n",
    "                    'FP': FP,\n",
    "                    'Accuracy': (TP+TN) / (TP+TN+FP+FN),\n",
    "                    'Sensitivity': TP / (TP+FN),\n",
    "                    'Specificity': TN / (FP+TN)\n",
    "                }\n",
    "\n",
    "            output_df = pd.DataFrame.from_dict(output_dict, orient='index')\n",
    "            output_df = target_item_df.join(output_df, on='MS2')\n",
    "\n",
    "            output_df.sort_values(by=['Specificity'], inplace=True)\n",
    "            output_df.to_csv(output_file, index=False, mode='a', header=header_flag)\n",
    "            header_flag = False # only include header for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1046/1046 [00:07<00:00, 133.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# combine all output into same csv file\n",
    "\n",
    "read_folder = os.path.join(os.getcwd(), algo_3_output_folder, 'non_combined_output')\n",
    "output_folder = os.path.join(os.getcwd(), algo_3_output_folder)\n",
    "cwd = os.getcwd()\n",
    "os.chdir(read_folder)\n",
    "listdir = glob.glob('*.csv')\n",
    "os.chdir(cwd)\n",
    "\n",
    "output_filename = os.path.join(output_folder, 'combined_output_algo_3.csv')\n",
    "\n",
    "combined_csv = pd.concat([ pd.read_csv(os.path.join(read_folder, f)) for f in tqdm(listdir) ], ignore_index=True, sort=False)\n",
    "combined_csv.to_csv(output_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
